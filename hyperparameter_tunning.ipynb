{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AbdElRahmanFarhan/box_semantic_segmentation/blob/main/hyperparameter_tunning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pycocotools\n",
        "!pip install coco-eval\n",
        "!pip install wandb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vBgw1-zix1lq",
        "outputId": "1b959aef-0208-4520-8181-85cc56f6424d"
      },
      "id": "vBgw1-zix1lq",
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.11/dist-packages (2.0.8)\n",
            "Requirement already satisfied: matplotlib>=2.1.0 in /usr/local/lib/python3.11/dist-packages (from pycocotools) (3.10.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from pycocotools) (2.0.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.1.0->pycocotools) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.1.0->pycocotools) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.1.0->pycocotools) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.1.0->pycocotools) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.1.0->pycocotools) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.1.0->pycocotools) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.1.0->pycocotools) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.1.0->pycocotools) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=2.1.0->pycocotools) (1.17.0)\n",
            "Requirement already satisfied: coco-eval in /usr/local/lib/python3.11/dist-packages (0.0.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from coco-eval) (2.0.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from coco-eval) (2.6.0+cu124)\n",
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.11/dist-packages (from coco-eval) (2.0.8)\n",
            "Requirement already satisfied: matplotlib>=2.1.0 in /usr/local/lib/python3.11/dist-packages (from pycocotools->coco-eval) (3.10.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->coco-eval) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch->coco-eval) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->coco-eval) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->coco-eval) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->coco-eval) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->coco-eval) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->coco-eval) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->coco-eval) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch->coco-eval) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch->coco-eval) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch->coco-eval) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch->coco-eval) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch->coco-eval) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch->coco-eval) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->coco-eval) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->coco-eval) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->coco-eval) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->coco-eval) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->coco-eval) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->coco-eval) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->coco-eval) (1.3.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.1.0->pycocotools->coco-eval) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.1.0->pycocotools->coco-eval) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.1.0->pycocotools->coco-eval) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.1.0->pycocotools->coco-eval) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.1.0->pycocotools->coco-eval) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.1.0->pycocotools->coco-eval) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.1.0->pycocotools->coco-eval) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.1.0->pycocotools->coco-eval) (2.9.0.post0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->coco-eval) (3.0.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=2.1.0->pycocotools->coco-eval) (1.17.0)\n",
            "Requirement already satisfied: wandb in /usr/local/lib/python3.11/dist-packages (0.19.10)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.11/dist-packages (from wandb) (8.1.8)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (3.1.44)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from wandb) (4.3.7)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<7,>=3.19.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (5.29.4)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (5.9.5)\n",
            "Requirement already satisfied: pydantic<3 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.11.3)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from wandb) (6.0.2)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.32.3)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.27.0)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.11/dist-packages (from wandb) (1.3.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from wandb) (75.2.0)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4 in /usr/local/lib/python3.11/dist-packages (from wandb) (4.13.2)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.17.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.12)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb) (0.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (2025.4.26)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OmcFnWMgEuMR",
        "outputId": "387c871d-edbf-4bd8-f05a-bcc03d0ffcf0"
      },
      "id": "OmcFnWMgEuMR",
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import wandb\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
        "wandb.login()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p0EhUEYrLbr7",
        "outputId": "e028783b-5527-4698-9a31-8a2b649bdc8c"
      },
      "id": "p0EhUEYrLbr7",
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "\n",
        "zip_file_path = '/content/drive/MyDrive/OSCD.zip'\n",
        "dataset_folder = '/content/drive/MyDrive/OSCD/'\n",
        "\n",
        "if len(os.listdir(dataset_folder)) == 0:\n",
        "  with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "      zip_ref.extractall(dataset_folder)\n",
        "\n",
        "  print(f\"Unzipped to: {dataset_folder}\")"
      ],
      "metadata": {
        "id": "tVioBrKYUq-B"
      },
      "id": "tVioBrKYUq-B",
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "train_folder = os.path.join(dataset_folder, 'coco_carton/oneclass_carton/images/train2017')\n",
        "val_folder = os.path.join(dataset_folder, 'coco_carton/oneclass_carton/images/val2017')\n",
        "train_annotation = os.path.join(dataset_folder, 'coco_carton/oneclass_carton/annotations/instances_train2017.json')\n",
        "val_annotation = os.path.join(dataset_folder, 'coco_carton/oneclass_carton/annotations/instances_val2017.json')"
      ],
      "metadata": {
        "id": "I1nBV1DvVSIY"
      },
      "id": "I1nBV1DvVSIY",
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torchvision.datasets import CocoDetection\n",
        "import torchvision.transforms as T\n",
        "from PIL import Image\n",
        "from torchvision.tv_tensors import Mask\n",
        "from torchvision.transforms.functional import to_tensor\n",
        "from skimage.draw import polygon as sk_polygon\n",
        "\n",
        "\n",
        "class OSCDDataset(CocoDetection):\n",
        "    def __init__(self, img_folder, ann_file):\n",
        "        super().__init__(img_folder, ann_file, transforms=None)\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "       return super().__len__()\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img, anns = super().__getitem__(idx)\n",
        "\n",
        "        if anns:\n",
        "          labels = []\n",
        "          areas = []\n",
        "          iscrowd = []\n",
        "          masks = []\n",
        "          boxes = []\n",
        "          ids = []\n",
        "          for ann in anns:\n",
        "              x, y, w, h = list(map(int, ann['bbox']))\n",
        "              boxes.append([x, y, x + w, y + h])\n",
        "              labels.append(ann['category_id'])\n",
        "              areas.append(ann['area'])\n",
        "              iscrowd.append(ann['iscrowd'])\n",
        "              mask = self.get_mask(ann['segmentation'], img.size[1], img.size[0])\n",
        "              masks.append(mask)\n",
        "              ids.append(ann['id'])\n",
        "\n",
        "          labels = torch.tensor(labels, dtype=torch.int64)\n",
        "          areas = torch.tensor(areas, dtype=torch.float16)\n",
        "          iscrowd = torch.tensor(iscrowd, dtype=torch.uint8)\n",
        "          boxes = torch.tensor(boxes, dtype=torch.int64)\n",
        "          masks = torch.stack(masks, dim=0)\n",
        "          ids = torch.tensor(ids, dtype=torch.int64)\n",
        "          img_id = torch.tensor(ann['image_id'], dtype=torch.int64)\n",
        "\n",
        "          target = {\n",
        "              \"boxes\": boxes,\n",
        "              \"labels\": labels,\n",
        "              \"image_id\": img_id,\n",
        "              \"ids\": ids,\n",
        "              \"area\": areas, # TODO: is it area or areas\n",
        "              \"iscrowd\": iscrowd,\n",
        "              \"masks\": Mask(masks),\n",
        "          }\n",
        "        else:\n",
        "          target = {}\n",
        "        img = to_tensor(img) # TODO: return an empty image\n",
        "        return img, target\n",
        "\n",
        "    def get_mask(self, segmentation, height, width):\n",
        "        mask = torch.zeros((height, width), dtype=torch.bool)\n",
        "        poly_x = segmentation[0][::2]\n",
        "        poly_y = segmentation[0][1::2]\n",
        "        rr, cc = sk_polygon(poly_y, poly_x, shape=(height, width))\n",
        "        mask[rr, cc] = 1\n",
        "        return mask\n"
      ],
      "metadata": {
        "id": "b8nnnWtw4QZ_"
      },
      "id": "b8nnnWtw4QZ_",
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RtgRXthL0IkM"
      },
      "id": "RtgRXthL0IkM",
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.transforms import v2 as T\n",
        "train_dataset = OSCDDataset(train_folder, train_annotation)\n",
        "val_dataset = OSCDDataset(val_folder, val_annotation)\n",
        "train_dataset_small = torch.utils.data.Subset(train_dataset, list(range(100)))\n",
        "val_dataset_small = torch.utils.data.Subset(val_dataset, list(range(10)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "id": "lfqBVyFN7_eL",
        "outputId": "998f5558-5889-4e07-c1ed-2ad92b798633"
      },
      "id": "lfqBVyFN7_eL",
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading annotations into memory...\n",
            "Done (t=1.71s)\n",
            "creating index...\n",
            "index created!\n",
            "loading annotations into memory...\n",
            "Done (t=0.14s)\n",
            "creating index...\n",
            "index created!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def collate_fn(batch):\n",
        "    images, targets = [], []\n",
        "    for (image, target) in batch:\n",
        "      if not target:\n",
        "        continue\n",
        "      else:\n",
        "        images.append(image)\n",
        "        targets.append(target)\n",
        "    return images, targets"
      ],
      "metadata": {
        "id": "ALq-GQQgYS-b"
      },
      "id": "ALq-GQQgYS-b",
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import matplotlib.pyplot as plt\n",
        "# from torchvision.utils import draw_bounding_boxes, draw_segmentation_masks\n",
        "# train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True, collate_fn=collate_fn, pin_memory=True, num_workers=2)\n",
        "# val_loader = DataLoader(val_dataset, batch_size=1, shuffle=True, collate_fn=collate_fn, pin_memory=True)\n",
        "# images, targets = next(iter(val_loader))\n",
        "# images = [image for image in images]\n",
        "# targets = [{k: v for k, v in t.items()} for t in targets]\n",
        "# img = images[0]\n",
        "# target = targets[0]\n",
        "# # plt_img = draw_bounding_boxes(img, target_boxes, colors=\"red\")\n",
        "# masks = (target[\"masks\"] > 0.9).squeeze(1)\n",
        "# plt_img = draw_segmentation_masks(img, masks, alpha=0.5, colors=\"blue\")\n",
        "# plt.figure(figsize=(12, 12))\n",
        "# plt.imshow(plt_img.cpu().permute(1, 2, 0))\n",
        "# plt.axis('off')\n",
        "# plt.show()"
      ],
      "metadata": {
        "id": "bd2jemhMzp6R"
      },
      "id": "bd2jemhMzp6R",
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision\n",
        "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
        "from torchvision.models.detection.mask_rcnn import MaskRCNNPredictor\n",
        "\n",
        "model = torchvision.models.detection.maskrcnn_resnet50_fpn(weights=\"DEFAULT\")\n",
        "in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
        "model.roi_heads.box_predictor = FastRCNNPredictor(in_features, 2)\n",
        "\n",
        "in_features_mask = model.roi_heads.mask_predictor.conv5_mask.in_channels\n",
        "model.roi_heads.mask_predictor = MaskRCNNPredictor(in_features_mask, 256, 2)"
      ],
      "metadata": {
        "id": "mAlUQafMhHWU"
      },
      "id": "mAlUQafMhHWU",
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import torchvision\n",
        "# from torchvision.models.detection import MaskRCNN\n",
        "# from torchvision.models.detection.backbone_utils import BackboneWithFPN\n",
        "# from torchvision.models.resnet import resnet18\n",
        "# from torchvision.models.detection.backbone_utils import BackboneWithFPN\n",
        "\n",
        "# resnet = resnet18(pretrained=True)\n",
        "# backbone = torch.nn.Sequential(\n",
        "#     resnet.conv1,\n",
        "#     resnet.bn1,\n",
        "#     resnet.relu,\n",
        "#     resnet.maxpool,\n",
        "#     resnet.layer1,\n",
        "#     resnet.layer2,\n",
        "#     resnet.layer3,\n",
        "#     resnet.layer4\n",
        "# )\n",
        "\n",
        "# return_layers = {\n",
        "#     '4': '0',  # layer1\n",
        "#     '5': '1',  # layer2\n",
        "#     '6': '2',  # layer3\n",
        "#     '7': '3',  # layer4\n",
        "# }\n",
        "\n",
        "# in_channels_list = [64, 128, 256, 512]\n",
        "# out_channels = 256\n",
        "\n",
        "# fpn_backbone = BackboneWithFPN(\n",
        "#     backbone,\n",
        "#     return_layers=return_layers,\n",
        "#     in_channels_list=in_channels_list,\n",
        "#     out_channels=out_channels\n",
        "# )\n",
        "\n",
        "# model = MaskRCNN(backbone=fpn_backbone, num_classes=2)"
      ],
      "metadata": {
        "id": "9eZ6OrIZeobc"
      },
      "id": "9eZ6OrIZeobc",
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model"
      ],
      "metadata": {
        "id": "KRTHGpYMe8-o"
      },
      "id": "KRTHGpYMe8-o",
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K6Xxv1Y0vhst",
        "outputId": "46493ccf-5998-4f07-9715-65536388b059"
      },
      "id": "K6Xxv1Y0vhst",
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "from tqdm.auto import tqdm\n",
        "from torch.amp import autocast, GradScaler\n",
        "\n",
        "def run_epoch(model, dataloader, optimizer, device, scaler, is_training):\n",
        "    model.train()\n",
        "    progress_bar = tqdm(total=len(dataloader), desc=\"Train\" if is_training else \"Valid\")  # Initialize a progress bar\n",
        "    batch_counter = 0\n",
        "    epoch_loss = 0.\n",
        "    epoch_losses = {\n",
        "      'loss_classifier': 0,\n",
        "      'loss_box_reg': 0.,\n",
        "      'loss_mask': 0.,\n",
        "      'loss_objectness': 0.,\n",
        "      'loss_rpn_box_reg': 0.}\n",
        "    for batch_id, (images, targets) in enumerate(dataloader):\n",
        "\n",
        "        images = [image.to(device) for image in images]\n",
        "        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
        "        if len(targets) == 0:\n",
        "          continue\n",
        "\n",
        "        batch_counter += 1\n",
        "        with autocast(device_type=device.type, dtype=torch.bfloat16):\n",
        "            if is_training:\n",
        "                losses = model(images, targets)\n",
        "            else:\n",
        "                with torch.no_grad():\n",
        "                    losses = model(images, targets)\n",
        "\n",
        "            loss = sum([loss for loss in losses.values()])\n",
        "\n",
        "        if is_training:\n",
        "            optimizer.zero_grad()\n",
        "            if scaler:\n",
        "                scaler.scale(loss).backward()\n",
        "                scaler.step(optimizer)\n",
        "                scaler.update()\n",
        "            else:\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "        epoch_losses = {k: v.item() + epoch_losses[k] for k, v in losses.items()}\n",
        "        loss_item = loss.item()\n",
        "        epoch_loss += loss_item\n",
        "        progress_bar_dict = dict(avg_loss=epoch_loss/(batch_counter+1))\n",
        "        progress_bar.set_postfix(progress_bar_dict)\n",
        "        progress_bar.update()\n",
        "        if is_training:\n",
        "          assert not math.isnan(loss_item) and math.isfinite(loss_item), \"Loss is NaN or infinite. Stopping training.\"\n",
        "    progress_bar.close()\n",
        "    epoch_losses = {k: v/(batch_counter + 1) for k, v in epoch_losses.items()}\n",
        "    return epoch_losses"
      ],
      "metadata": {
        "id": "CJAiEWO6WzXO"
      },
      "id": "CJAiEWO6WzXO",
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sweep_config = {\n",
        "    'method': 'random'\n",
        "    }\n",
        "\n",
        "metric = {\n",
        "    'name': 'val_loss',\n",
        "    'goal': 'minimize'\n",
        "    }\n",
        "\n",
        "sweep_config['metric'] = metric\n",
        "parameters_dict = {\n",
        "    'epochs': {\n",
        "        'values': [5]\n",
        "        },\n",
        "    'lr': {\n",
        "        'values': [5e-4]\n",
        "        },\n",
        "    'weight_decay': {\n",
        "          'values': [1e-2]\n",
        "        },\n",
        "    'bs': {\n",
        "          'values': [2]\n",
        "        },\n",
        "    'save_model_every': {\n",
        "          'values': [5]\n",
        "        },\n",
        "    'scheduler': {\n",
        "          'values': ['step']\n",
        "        },\n",
        "    'step_size': {\n",
        "          'values': [5]\n",
        "        },\n",
        "    'gamma': {\n",
        "          'values': [0.1]\n",
        "        },\n",
        "    'optimizer_type': {\n",
        "          'values': ['adamw']\n",
        "        },\n",
        "    }\n",
        "\n",
        "sweep_config['parameters'] = parameters_dict"
      ],
      "metadata": {
        "id": "fCxX_I_2EWcU"
      },
      "id": "fCxX_I_2EWcU",
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sweep_id = wandb.sweep(sweep_config, project=\"box_segmentation\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U4mB2Dm_EgRu",
        "outputId": "b4177535-9fa8-4d97-c426-2cc99c1e6d3c"
      },
      "id": "U4mB2Dm_EgRu",
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Create sweep with ID: 4d4rpjsb\n",
            "Sweep URL: https://wandb.ai/abdelrahman-farhan/box_segmentation/sweeps/4d4rpjsb\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.optim import AdamW\n",
        "import datetime\n",
        "\n",
        "def train(config=None):\n",
        "  with wandb.init(config=config):\n",
        "    config = wandb.config\n",
        "    lr = config.lr\n",
        "    weight_decay = config.weight_decay\n",
        "    epochs = config.epochs\n",
        "    bs = config.bs\n",
        "    save_every = config.save_model_every\n",
        "    freeze_backbone = config.freeze_backbone\n",
        "\n",
        "    model.to(device)\n",
        "    params = [p for p in model.parameters() if p.requires_grad]\n",
        "    optimizer_type = config.optimizer_type\n",
        "\n",
        "    if optimizer_type == 'sgd':\n",
        "      optimizer = torch.optim.SGD(params, lr=lr, momentum=0.9, weight_decay=weight_decay)\n",
        "    elif optimizer_type == 'adamw':\n",
        "      optimizer = torch.optim.AdamW(params, lr=lr, weight_decay=weight_decay, amsgrad=True)\n",
        "\n",
        "    scheduler = config.scheduler\n",
        "    scheduler_step = config.step_size\n",
        "    gamma = config.gamma\n",
        "    if scheduler == 'step':\n",
        "      lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=scheduler_step, gamma=gamma)\n",
        "    elif scheduler == 'linear':\n",
        "      lr_scheduler = torch.optim.lr_scheduler.LinearLR(optimizer, start_factor=1.0, end_factor=0.1, total_iters=epochs)\n",
        "    elif scheduler == 'cyclic':\n",
        "      lr_scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=lr, total_steps=epochs)\n",
        "\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=bs, shuffle=True, collate_fn=collate_fn, pin_memory=True, num_workers=12)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=bs, shuffle=True, collate_fn=collate_fn, pin_memory=True, num_workers=12)\n",
        "\n",
        "    scaler = GradScaler()\n",
        "    for epoch in tqdm(range(epochs), desc=\"Epochs\"):\n",
        "\n",
        "        train_losses = run_epoch(model, train_loader, optimizer, device, scaler, is_training=True)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            valid_losses = run_epoch(model, val_loader, None, device, scaler, is_training=False)\n",
        "        lr_scheduler.step()\n",
        "\n",
        "        train_losses = {f'train/{k}': v for k, v in train_losses.items()}\n",
        "        wandb.log(train_losses)\n",
        "        train_loss = sum(train_losses.values())\n",
        "        wandb.log({'train/loss': train_loss})\n",
        "\n",
        "        valid_losses = {f'valid/{k}': v for k, v in valid_losses.items()}\n",
        "        wandb.log(valid_losses)\n",
        "        valid_loss = sum(valid_losses.values())\n",
        "        wandb.log({'valid/loss': valid_loss})\n",
        "\n",
        "        wandb.log({'lr': lr_scheduler.get_last_lr()[0]})\n",
        "\n",
        "        if (epoch+1) % save_every == 0:\n",
        "          model_path = os.path.join(dataset_folder, 'model', f'model_{wandb.run.sweep_id}_{(epoch+1)}.pth')\n",
        "          torch.save(model.state_dict(), model_path)"
      ],
      "metadata": {
        "id": "uvgNzhCcYAFD"
      },
      "id": "uvgNzhCcYAFD",
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.agent(sweep_id, train, count=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "w7fMbRGLGtFq",
        "outputId": "2a92515c-a5c3-42e7-bd7e-b1f1233a0020"
      },
      "id": "w7fMbRGLGtFq",
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: u228du1r with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbs: 2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tgamma: 0.1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.0005\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_type: adamw\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tsave_model_every: 5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler: step\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tstep_size: 5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.01\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.10"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250501_214323-u228du1r</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/abdelrahman-farhan/box_segmentation/runs/u228du1r' target=\"_blank\">vivid-sweep-1</a></strong> to <a href='https://wandb.ai/abdelrahman-farhan/box_segmentation' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/abdelrahman-farhan/box_segmentation/sweeps/4d4rpjsb' target=\"_blank\">https://wandb.ai/abdelrahman-farhan/box_segmentation/sweeps/4d4rpjsb</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/abdelrahman-farhan/box_segmentation' target=\"_blank\">https://wandb.ai/abdelrahman-farhan/box_segmentation</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View sweep at <a href='https://wandb.ai/abdelrahman-farhan/box_segmentation/sweeps/4d4rpjsb' target=\"_blank\">https://wandb.ai/abdelrahman-farhan/box_segmentation/sweeps/4d4rpjsb</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/abdelrahman-farhan/box_segmentation/runs/u228du1r' target=\"_blank\">https://wandb.ai/abdelrahman-farhan/box_segmentation/runs/u228du1r</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/wandb_config.py\", line 165, in __getattr__\n",
            "    return self.__getitem__(key)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/wandb_config.py\", line 130, in __getitem__\n",
            "    return self._items[key]\n",
            "           ~~~~~~~~~~~^^^^^\n",
            "KeyError: 'freeze_backbone'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"<ipython-input-66-131b12f601b8>\", line 12, in train\n",
            "    freeze_backbone = config.freeze_backbone\n",
            "                      ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/wandb_config.py\", line 167, in __getattr__\n",
            "    raise AttributeError(\n",
            "AttributeError: <class 'wandb.sdk.wandb_config.Config'> object has no attribute 'freeze_backbone'\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">vivid-sweep-1</strong> at: <a href='https://wandb.ai/abdelrahman-farhan/box_segmentation/runs/u228du1r' target=\"_blank\">https://wandb.ai/abdelrahman-farhan/box_segmentation/runs/u228du1r</a><br> View project at: <a href='https://wandb.ai/abdelrahman-farhan/box_segmentation' target=\"_blank\">https://wandb.ai/abdelrahman-farhan/box_segmentation</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250501_214323-u228du1r/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run u228du1r errored:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Traceback (most recent call last):\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/wandb_config.py\", line 165, in __getattr__\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return self.__getitem__(key)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/wandb_config.py\", line 130, in __getitem__\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return self._items[key]\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ~~~~~~~~~~~^^^^^\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m KeyError: 'freeze_backbone'\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m The above exception was the direct cause of the following exception:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Traceback (most recent call last):\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/wandb/agents/pyagent.py\", line 306, in _run_job\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self._function()\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"<ipython-input-66-131b12f601b8>\", line 12, in train\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     freeze_backbone = config.freeze_backbone\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m                       ^^^^^^^^^^^^^^^^^^^^^^\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/wandb_config.py\", line 167, in __getattr__\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     raise AttributeError(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m AttributeError: <class 'wandb.sdk.wandb_config.Config'> object has no attribute 'freeze_backbone'\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"test\")"
      ],
      "metadata": {
        "id": "kHp7MAYABg9-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b402877-3509-4f9b-8d24-4ea119805f7a"
      },
      "id": "kHp7MAYABg9-",
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1Y5NEJ2XxsPn"
      },
      "id": "1Y5NEJ2XxsPn",
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "o0l4mQSIxsKu"
      },
      "id": "o0l4mQSIxsKu",
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print([p.requires_grad for p in model.backbone.parameters()])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F5RpEif8xZG1",
        "outputId": "0e184372-48b6-4317-b2d8-f60d68291cfc"
      },
      "id": "F5RpEif8xZG1",
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[False, False, False, False, False, False, False, False, False, False, False, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vT3Rlmdgxpn9"
      },
      "id": "vT3Rlmdgxpn9",
      "execution_count": 69,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}